{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d312ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import toml\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "sys.path.append(os.path.abspath(\"data_management\"))\n",
    "sys.path.append(os.path.abspath(\"onnx_models\"))\n",
    "sys.path.append(os.path.abspath(\"hardware\"))\n",
    "\n",
    "import data_preprocessing as dprep\n",
    "import data_postprocessing as dpostp\n",
    "import onnx_inference as onnx_inf\n",
    "import validate as val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1347694",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_cfg = toml.load('yolov5n.toml')\n",
    "inf_exec = yolo_cfg['inf_exec']\n",
    "imgsz = yolo_cfg['input_data']['imgsz']\n",
    "conf_thres = yolo_cfg['predictor']['conf_thres']\n",
    "iou_thres = yolo_cfg['predictor']['iou_thres']\n",
    "classes = yolo_cfg['predictor']['classes']\n",
    "if not classes:\n",
    "    classes = None\n",
    "onnx_model_path = yolo_cfg['onnx_model_path']\n",
    "if inf_exec == \"fpga\":\n",
    "    onnx_model_path = f\"{onnx_model_path.split('.onnx')[0]}_head.onnx\"\n",
    "visualize = yolo_cfg['visualize']\n",
    "val_data_path = yolo_cfg['val_data_path']\n",
    "out_img_path = yolo_cfg['out_img_path']\n",
    "input_source = yolo_cfg['source']\n",
    "bitstream_path = yolo_cfg['hardware']['bitstream_path']\n",
    "weights_lookup_table = yolo_cfg['hardware']['weights_lookup_table']\n",
    "weights_path = yolo_cfg['hardware']['weights_path']\n",
    "input_bp = yolo_cfg['hardware']['input_binary_point']\n",
    "output_bp = yolo_cfg['hardware']['output_binary_point']\n",
    "fifo_depth = yolo_cfg['hardware']['fifo_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb53863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride, names, session, output_names = onnx_inf.load_model(onnx_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a657c9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if inf_exec == \"fpga\":\n",
    "    import hw_partition as hw_part\n",
    "    #########################\n",
    "    ### fpgaConvNet Setup ###\n",
    "    #########################\n",
    "\n",
    "    # initialise partition\n",
    "    partition = hw_part.Partition(bitstream_path, 5) \n",
    "\n",
    "    # add input buffers\n",
    "    partition.add_input_buffer(0, 0, [320, 320, 3], bp=input_bp)\n",
    "\n",
    "    # add output buffers\n",
    "    partition.add_output_buffer(2, 2, [40, 40, 256], bp=output_bp, streams=2)\n",
    "    partition.add_output_buffer(3, 3, [20, 20, 256], bp=output_bp, streams=2)\n",
    "    partition.add_output_buffer(4, 4, [10, 10, 256], bp=output_bp, streams=2)\n",
    "\n",
    "    # create fifos\n",
    "    partition.add_fifo(0, 0, 2, 40*40*64 , burst=fifo_depth[0])\n",
    "    partition.add_fifo(1, 1, 1, 20*20*128, burst=fifo_depth[1])\n",
    "\n",
    "    # # setup hardware\n",
    "    partition.reset_hardware()\n",
    "\n",
    "    # get the lookup table for the weights\n",
    "    with open(weights_lookup_table, \"r\") as f:\n",
    "        lookup = json.load(f)\n",
    "\n",
    "    # iterate over the weights\n",
    "    for layer, idx in lookup.items():\n",
    "\n",
    "        # allocate weights and load them\n",
    "        start_time = time.perf_counter() \n",
    "        partition.reload_weights(idx, f\"{weights_path}/{layer}.dat\")\n",
    "        pred_time = (time.perf_counter() - start_time)*1000\n",
    "        print(f\"[{idx}] {layer} loaded! ({pred_time:.2f} ms)\")\n",
    "\n",
    "    # setup hardware\n",
    "    partition.reset_hardware()\n",
    "    partition.start_hardware() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d099e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val.get_val_data(val_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0263484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Class: all\n",
      "Images: 126\n",
      "Instances: 929\n",
      "Precision: 0.5553\n",
      "Recall: 0.4243\n",
      "mAP@0.5: 0.4562\n",
      "mAP@0.5:0.95: 0.2902\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "iouv = np.linspace(0.5, 0.95, 10)\n",
    "niou = iouv.size\n",
    "seen = 0\n",
    "stats = []\n",
    "\n",
    "for img, labels in val_data:\n",
    "\n",
    "    orig_img = img.copy()\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = dprep.img_preprocess(img, imgsz, stride)\n",
    "\n",
    "    if inf_exec == \"cpu\":\n",
    "        predictions, pred_time = onnx_inf.model_inf(img, session, output_names)\n",
    "    elif inf_exec == \"fpga\":\n",
    "        out0, out1, out2, _ = hw_part.run_fpgaconvnet(partition, img[0])\n",
    "        predictions = session.run(output_names, {\n",
    "            \"/model.24/m.0/Conv_output_0\": np.expand_dims(out0[:255,:,:], axis=0),\n",
    "            \"/model.24/m.1/Conv_output_0\": np.expand_dims(out1[:255,:,:], axis=0),\n",
    "            \"/model.24/m.2/Conv_output_0\": np.expand_dims(out2[:255,:,:], axis=0),\n",
    "        })[0]\n",
    "\n",
    "    predictions = dpostp.yolo_nms(predictions, conf_thres=0.001, iou_thres=0.6, classes=classes)\n",
    "\n",
    "    for pred in predictions:\n",
    "        seen += 1\n",
    "\n",
    "        nl, npr = labels.shape[0], pred.shape[0]  # number of labels, predictions\n",
    "\n",
    "        correct = np.zeros((npr, niou), dtype=bool)\n",
    "\n",
    "        if npr == 0:\n",
    "            if nl:\n",
    "                stats.append((correct, *np.zeros((2, 0)), labels[:, 0]))\n",
    "\n",
    "        predn = pred.copy()\n",
    "        predn[:, :4] = dpostp.scale_boxes((imgsz, imgsz), predn[:, :4], orig_img.shape).round()\n",
    "\n",
    "        if nl:\n",
    "            labelsn = labels.copy()\n",
    "\n",
    "            correct = val.process_batch(predn, labelsn, iouv)\n",
    "\n",
    "        stats.append((correct, pred[:, 4], pred[:, 5], labels[:, 0])) # (correct, conf, pcls, tcls)\n",
    "        \n",
    "# Compute metrics\n",
    "stats = [np.concatenate(x, 0) for x in zip(*stats)]\n",
    "if len(stats) and stats[0].any():\n",
    "    tp, fp, p, r, f1, ap, ap_class = val.ap_per_class(*stats, names=names)\n",
    "    ap50, ap = ap[:, 0], ap.mean(1)  # AP@0.5, AP@0.5:0.95\n",
    "    mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
    "nt = np.bincount(stats[3].astype(int), minlength=80)  # number of targets per class\n",
    "\n",
    "# Print results\n",
    "print(\"*\"*40)\n",
    "print(\"Class: {}\".format(\"all\"))\n",
    "print(\"Images: {}\".format(seen))\n",
    "print(\"Instances: {}\".format(nt.sum()))\n",
    "print(\"Precision: {:.4f}\".format(mp))\n",
    "print(\"Recall: {:.4f}\".format(mr))\n",
    "print(\"mAP@0.5: {:.4f}\".format(map50))\n",
    "print(\"mAP@0.5:0.95: {:.4f}\".format(map))\n",
    "print(\"*\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
